{
    "page_content": "highlight Gemini’s native multimodality and indicate early signs of Gemini's more complex reasoning abilities.See more details in our Gemini technical report. Gemini surpasses state-of-the-art performance on a range of multimodal benchmarks. Next-generation capabilitiesUntil now, the standard approach to creating multimodal models involved training separate components for different modalities and then stitching them together to roughly mimic some of this functionality. These models can sometimes be good at performing certain tasks, like describing images, but struggle with more conceptual and complex reasoning.We designed Gemini to be natively multimodal, pre-trained from the start on different modalities. Then we fine-tuned it with additional multimodal data to further refine its effectiveness. This helps Gemini seamlessly understand and reason about all kinds of inputs from the ground up, far better than existing multimodal models — and its capabilities are state of the art in",
    "metadata": {
        "source": "https://blog.google/technology/ai/google-gemini-ai/",
        "title": "Introducing Gemini: Google’s most capable AI model yet",
        "description": "Gemini is our most capable and general model, built to be multimodal and optimized for three different sizes: Ultra, Pro and Nano.",
        "language": "en-us",
        "chunk_number": 93
    }
}